# ðŸŽ¯ AnÃ¡lise CrÃ­tica e Melhorias Propostas para o Modelo LSTM

## ðŸ“Š DiagnÃ³stico do Problema Atual

### âŒ Sintomas Identificados:

1. **PrevisÃµes constantes (~0.27)** - O modelo estÃ¡ prevendo sempre a mÃ©dia
2. **Alta variabilidade nÃ£o capturada** - Valores reais variam 0.1-0.4, previsÃµes ficam em 0.26-0.28
3. **UNDERFITTING** - NÃ£o hÃ¡ overfitting, mas o modelo nÃ£o aprende padrÃµes complexos

### ðŸ” Causas ProvÃ¡veis:

1. **Janela temporal muito curta** (4 semanas) - Pouco contexto histÃ³rico
2. **Modelo muito simples** (50 neurÃ´nios) - Baixa capacidade de aprendizado
3. **Poucas amostras** (~50 semanas) - Dados insuficientes para treinamento robusto
4. **Features limitadas** (6 features) - Falta informaÃ§Ã£o contextual

---

## ðŸ› ï¸ Melhorias Propostas (Por Prioridade)

### â­ **Prioridade 1: Aumentar Janela Temporal**

**Atual:** 4 semanas â†’ **Proposta:** 8-12 semanas

**Por quÃª:**
- Acidentes tÃªm padrÃµes sazonais e mensais
- Mais contexto = melhor compreensÃ£o de tendÃªncias
- **Risco de overfitting: BAIXO** (apenas mais contexto, nÃ£o mais parÃ¢metros)

**MudanÃ§a no cÃ³digo:**
```python
# ANTES:
n_passos_para_tras = 4  # 4 semanas de contexto

# DEPOIS:
n_passos_para_tras = 8  # 8 semanas de contexto
```

**Impacto esperado:** +15-20% de melhoria

---

### â­ **Prioridade 2: Adicionar Features de Lag (HistÃ³rico)**

**Atual:** 6 features â†’ **Proposta:** 10-12 features

**Adicionar:**
```python
# Features de lag (histÃ³rico das Ãºltimas semanas)
weekly_df['prop_severos_lag1'] = weekly_df.groupby('uf')['prop_severos'].shift(1)
weekly_df['prop_severos_lag2'] = weekly_df.groupby('uf')['prop_severos'].shift(2)
weekly_df['prop_severos_lag3'] = weekly_df.groupby('uf')['prop_severos'].shift(3)

# MÃ©dia mÃ³vel
weekly_df['prop_severos_ma3'] = weekly_df.groupby('uf')['prop_severos'].rolling(3).mean().reset_index(0, drop=True)

# TendÃªncia
weekly_df['prop_severos_tendencia'] = weekly_df.groupby('uf')['prop_severos'].diff()

# Volatilidade
weekly_df['prop_severos_volatilidade'] = weekly_df.groupby('uf')['prop_severos'].rolling(3).std().reset_index(0, drop=True)
```

**Impacto esperado:** +20-25% de melhoria
**Risco de overfitting: BAIXO** (features derivadas dos dados reais)

---

### â­ **Prioridade 3: Aumentar Capacidade do Modelo**

**Atual:** 2 camadas LSTM (50, 50) â†’ **Proposta:** 3 camadas LSTM (64, 32, 16)

```python
# MODELO MELHORADO
model = Sequential()

# Primeira camada LSTM (aumentar neurÃ´nios)
model.add(LSTM(units=64, return_sequences=True, input_shape=(n_passos_para_tras, n_features)))
model.add(Dropout(0.2))

# Segunda camada LSTM
model.add(LSTM(units=32, return_sequences=True))
model.add(Dropout(0.2))

# Terceira camada LSTM (adicional)
model.add(LSTM(units=16))
model.add(Dropout(0.2))

# Camada densa intermediÃ¡ria
model.add(Dense(units=8, activation='relu'))
model.add(Dropout(0.2))

# Camada de saÃ­da
model.add(Dense(units=1, activation='linear'))
```

**Impacto esperado:** +10-15% de melhoria
**Risco de overfitting: MÃ‰DIO** (mais parÃ¢metros, mas com Dropout adequado)

---

### ðŸ”¸ **Prioridade 4: Ajustar HiperparÃ¢metros**

**Learning Rate mais baixo:**
```python
# ANTES:
optimizer = Adam(learning_rate=0.001)

# DEPOIS:
optimizer = Adam(learning_rate=0.0005)  # Mais conservador
```

**Early Stopping menos restritivo:**
```python
# ANTES:
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# DEPOIS:
early_stop = EarlyStopping(
    monitor='val_loss', 
    patience=15,  # Mais paciÃªncia
    min_delta=0.001,  # MudanÃ§a mÃ­nima significativa
    restore_best_weights=True
)
```

**Mais Ã©pocas:**
```python
# ANTES:
history = model.fit(..., epochs=100, ...)

# DEPOIS:
history = model.fit(..., epochs=150, ...)  # Mais tempo para aprender
```

**Impacto esperado:** +5-10% de melhoria
**Risco de overfitting: BAIXO** (com early stopping adequado)

---

### ðŸ”¸ **Prioridade 5: Usar Todos os Dados (NÃ£o Filtrar Estados)**

**Atual:** Filtra 10 estados â†’ **Proposta:** Usar TODOS os estados

```python
# REMOVER esta linha:
# df_multi_estados = weekly_df[weekly_df['uf'].isin(estados_principais)].copy()

# USAR:
df_multi_estados = weekly_df.copy()  # Todos os estados
```

**Por quÃª:**
- Mais amostras = melhor generalizaÃ§Ã£o
- Diversidade geogrÃ¡fica = padrÃµes mais ricos

**Impacto esperado:** +10-15% de melhoria
**Risco de overfitting: BAIXO** (mais dados Ã© sempre melhor)

---

## ðŸ“ˆ Plano de ImplementaÃ§Ã£o Gradual

### Fase 1: MudanÃ§as Seguras (Baixo Risco)
1. âœ… Aumentar janela temporal para 8 semanas
2. âœ… Adicionar features de lag
3. âœ… Usar todos os estados

**Resultado esperado:** MAE de ~0.12 â†’ ~0.08 (33% de melhoria)

### Fase 2: Ajustes de Modelo (Risco Controlado)
4. âœ… Aumentar capacidade do modelo (3 camadas)
5. âœ… Ajustar hiperparÃ¢metros

**Resultado esperado:** MAE de ~0.08 â†’ ~0.06 (50% de melhoria total)

---

## âš ï¸ Sinais de Alerta para Overfitting

Monitore estes indicadores:

### âŒ OVERFITTING se:
- Loss de validaÃ§Ã£o **SOBE** enquanto loss de treino continua caindo
- Gap entre loss de treino e validaÃ§Ã£o **AUMENTA** (>50%)
- MAE de validaÃ§Ã£o >> MAE de treino

### âœ… BOA PERFORMANCE se:
- Loss de treino e validaÃ§Ã£o caem juntos
- Gap pequeno (<20%)
- PrevisÃµes capturam variabilidade dos dados reais

---

## ðŸŽ¯ MÃ©tricas Alvo

| MÃ©trica | Atual | Meta Realista | Meta Otimista |
|---------|-------|---------------|---------------|
| MAE | 0.12-0.13 | 0.08-0.09 | 0.06-0.07 |
| RÂ² | ~0.10-0.20 | 0.50-0.60 | 0.70-0.80 |
| Variabilidade Capturada | 10-15% | 50-60% | 70-80% |

---

## ðŸ”„ PrÃ³ximos Passos

1. **Implementar melhorias da Fase 1** (seguras)
2. **Treinar e avaliar**
3. **Se resultados melhorarem:** Implementar Fase 2
4. **Se overfitting aparecer:** Reverter mudanÃ§as

---

## ðŸ“ Notas Importantes

### Por que NÃƒO Ã© overfitting atual:
- Loss de treino e validaÃ§Ã£o estÃ£o **prÃ³ximos**
- MAE de treino e validaÃ§Ã£o sÃ£o **similares**
- Problema Ã© **underfitting** (modelo muito simples)

### Como evitar overfitting ao melhorar:
- âœ… Manter Dropout (0.2-0.3)
- âœ… Usar Early Stopping
- âœ… Mais dados (todos os estados)
- âœ… ValidaÃ§Ã£o adequada (85/15 split temporal)
- âœ… Monitorar Loss de validaÃ§Ã£o

---

**Desenvolvido pela equipe Big 5**

*Ãšltima atualizaÃ§Ã£o: 25/10/2025*

