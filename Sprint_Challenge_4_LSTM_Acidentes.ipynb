{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš— Sprint Challenge 4 â€“ PrevisÃ£o de Acidentes com LSTMs\n",
    "## Case Sompo: Antecipando PadrÃµes de Risco em Rodovias Brasileiras\n",
    "\n",
    "---\n",
    "\n",
    "**Equipe Big 5**\n",
    "- Lucca Phelipe Masini - RM 564121\n",
    "- Luiz Henrique Poss - RM 562177\n",
    "- Luis Fernando de Oliveira Salgado - RM 561401\n",
    "- Igor PaixÃ£o Sarak - RM 563726\n",
    "- Bernardo Braga Perobeli - RM 562468\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Target Escolhido: Prever NÃºmero Total de Acidentes\n",
    "\n",
    "**Objetivo**: Prever o **nÃºmero total de acidentes** que ocorrerÃ£o em cada semana por estado.\n",
    "\n",
    "- **Target**: Contagem de acidentes (valores inteiros)\n",
    "- **InterpretaÃ§Ã£o**: Quantos acidentes esperamos na prÃ³xima semana\n",
    "- **AplicaÃ§Ã£o prÃ¡tica**: AlocaÃ§Ã£o de recursos (patrulhas, ambulÃ¢ncias)\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "Escolhemos **prever nÃºmero de acidentes** porque:\n",
    "\n",
    "1. âœ… **PadrÃµes temporais claros** - VariaÃ§Ã£o dia Ãºtil vs fim de semana, feriados, sazonalidade\n",
    "2. âœ… **Features histÃ³ricas sÃ£o preditivas** - NÃºmero de acidentes nas Ãºltimas semanas ajuda a prever a prÃ³xima\n",
    "3. âœ… **LSTM ideal para sÃ©ries temporais** - Captura dependÃªncias de longo prazo\n",
    "4. âœ… **MÃ©tricas intuitivas** - MAE mostra erro mÃ©dio em nÃºmero de acidentes (ex: Â±5 acidentes/semana)\n",
    "5. âœ… **Valor prÃ¡tico real** - Gestores podem planejar operaÃ§Ãµes baseado em volume esperado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Passo 1: InstalaÃ§Ã£o e ImportaÃ§Ã£o de Bibliotecas\n",
    "\n",
    "Primeiro, vamos instalar e importar todas as bibliotecas necessÃ¡rias para o projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl --quiet\n",
    "print(\"âœ… Bibliotecas instaladas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¥ Passo 2: Carregamento dos Dados\n",
    "\n",
    "Carregamos os dados diretamente do GitHub para garantir reprodutibilidade total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“š Bibliotecas importadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Passo 3: PrÃ©-processamento e CriaÃ§Ã£o da VariÃ¡vel Target\n",
    "\n",
    "Criamos a variÃ¡vel binÃ¡ria `severo` que identifica acidentes com mortos ou feridos graves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ Baixando dataset da PRF do GitHub...\")\n",
    "\n",
    "github_raw_url = 'https://raw.githubusercontent.com/9luis7/lstm-acidentes-prf/main/dados/datatran2025.xlsx'\n",
    "output_filename = 'dados_acidentes.xlsx'\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve(github_raw_url, output_filename)\n",
    "    df = pd.read_excel(output_filename)\n",
    "    print(f\"âœ… Dataset carregado: {len(df):,} acidentes\")\n",
    "    print(\"\\nğŸ“Š PerÃ­odo:\", df['data_inversa'].min(), \"atÃ©\", df['data_inversa'].max())\n",
    "    print(\"ğŸ“Š Estados:\", df['uf'].nunique(), \"UFs\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Passo 4: AgregaÃ§Ã£o Semanal\n",
    "\n",
    "Transformamos acidentes individuais em sÃ©ries temporais semanais por estado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ Criando variÃ¡vel target 'severo'...\")\n",
    "\n",
    "df['horario'] = pd.to_datetime(df['horario'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "df['severo'] = ((df['mortos'] > 0) | (df['feridos_graves'] > 0)).astype(int)\n",
    "\n",
    "colunas_relevantes = ['data_inversa', 'horario', 'uf', 'br', 'km', 'pessoas', 'veiculos', 'severo']\n",
    "df_limpo = df[colunas_relevantes].copy()\n",
    "df_limpo['horario'].fillna(pd.to_datetime('12:00:00').time(), inplace=True)\n",
    "\n",
    "print(\"âœ… VariÃ¡vel 'severo' criada!\")\n",
    "print(\"\\nğŸ“Š DistribuiÃ§Ã£o:\")\n",
    "print(df_limpo['severo'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¨ Passo 5: Feature Engineering\n",
    "\n",
    "Criamos 12 features enriquecidas: temporais, sazonalidade e histÃ³rico (lags).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Agregando dados em sÃ©ries temporais semanais...\")\n",
    "\n",
    "df_indexed = df_limpo.set_index('data_inversa')\n",
    "\n",
    "weekly_df = df_indexed.groupby([pd.Grouper(freq='W'), 'uf']).agg(\n",
    "    total_acidentes=('severo', 'count'),\n",
    "    acidentes_severos=('severo', 'sum'),\n",
    "    pessoas_total=('pessoas', 'sum'),\n",
    "    veiculos_total=('veiculos', 'sum'),\n",
    "    pessoas_media=('pessoas', 'mean'),\n",
    "    veiculos_media=('veiculos', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "weekly_df['prop_severos'] = np.where(\n",
    "    weekly_df['total_acidentes'] > 0,\n",
    "    weekly_df['acidentes_severos'] / weekly_df['total_acidentes'],\n",
    "    0\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dados agregados: {len(weekly_df):,} semanas Ã— estados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¢ Passo 6: CriaÃ§Ã£o de SequÃªncias Temporais\n",
    "\n",
    "Criamos janelas de 8 semanas para prever a semana seguinte. Normalizamos os dados com MinMaxScaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¨ Criando features temporais e de histÃ³rico...\")\n",
    "\n",
    "# Temporais\n",
    "weekly_df['dia_semana'] = weekly_df['data_inversa'].dt.dayofweek\n",
    "weekly_df['mes'] = weekly_df['data_inversa'].dt.month\n",
    "weekly_df['fim_semana'] = weekly_df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Sazonalidade\n",
    "weekly_df['sazonalidade_sen'] = np.sin(2 * np.pi * weekly_df['data_inversa'].dt.dayofyear / 365)\n",
    "weekly_df['sazonalidade_cos'] = np.cos(2 * np.pi * weekly_df['data_inversa'].dt.dayofyear / 365)\n",
    "\n",
    "# Lags\n",
    "for lag in [1, 2, 3]:\n",
    "    weekly_df[f'prop_severos_lag{lag}'] = weekly_df.groupby('uf')['prop_severos'].shift(lag)\n",
    "\n",
    "# EstatÃ­sticas\n",
    "weekly_df['prop_severos_ma3'] = weekly_df.groupby('uf')['prop_severos'].rolling(3).mean().reset_index(0, drop=True)\n",
    "weekly_df['prop_severos_tendencia'] = weekly_df.groupby('uf')['prop_severos'].diff()\n",
    "weekly_df['prop_severos_volatilidade'] = weekly_df.groupby('uf')['prop_severos'].rolling(3).std().reset_index(0, drop=True)\n",
    "\n",
    "print(\"âœ… Features criadas!\")\n",
    "print(f\"   Total: {len(weekly_df.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Passo 7: PreparaÃ§Ã£o dos Dados\n",
    "\n",
    "Criamos features baseadas em contagens e caracterÃ­sticas temporais dos acidentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ—ï¸ Passo 8: ConstruÃ§Ã£o do Modelo LSTM\n",
    "\n",
    "**Arquitetura Otimizada para SÃ©ries Temporais:**\n",
    "- 2 camadas LSTM (128 â†’ 64 neurÃ´nios) - captura padrÃµes temporais complexos\n",
    "- 2 camadas Dense (32 â†’ 16 neurÃ´nios) - processamento nÃ£o-linear\n",
    "- Output (1 neurÃ´nio, linear) - previsÃ£o contÃ­nua\n",
    "- Loss: MAE (Mean Absolute Error)\n",
    "- MÃ©tricas: MAE, MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"ğŸ”¢ Preparando sequÃªncias para LSTM - PrevisÃ£o de NÃºmero de Acidentes...\")\n",
    "\n",
    "# Criar features baseadas em CONTAGEM de acidentes\n",
    "df_features = weekly_df.set_index('data_inversa').sort_index()\n",
    "\n",
    "# Features: total de acidentes + caracterÃ­sticas temporais + lags\n",
    "df_features['total_acidentes_norm'] = df_features['total_acidentes'] / df_features['total_acidentes'].max()\n",
    "\n",
    "# Lags do nÃºmero de acidentes (Ãºltimas 3 semanas)\n",
    "for lag in [1, 2, 3]:\n",
    "    df_features[f'acidentes_lag{lag}'] = df_features.groupby(level=0)['total_acidentes'].shift(lag)\n",
    "\n",
    "# MÃ©dia mÃ³vel de 3 semanas\n",
    "df_features['acidentes_ma3'] = df_features['total_acidentes'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# TendÃªncia (diferenÃ§a semana atual vs anterior)\n",
    "df_features['acidentes_tendencia'] = df_features['total_acidentes'].diff()\n",
    "\n",
    "# Volatilidade (desvio padrÃ£o mÃ³vel 3 semanas)\n",
    "df_features['acidentes_volatilidade'] = df_features['total_acidentes'].rolling(window=3, min_periods=1).std()\n",
    "\n",
    "features_colunas = [\n",
    "    'total_acidentes', 'pessoas_media', 'veiculos_media', 'fim_semana',\n",
    "    'sazonalidade_sen', 'sazonalidade_cos',\n",
    "    'acidentes_lag1', 'acidentes_lag2', 'acidentes_lag3',\n",
    "    'acidentes_ma3', 'acidentes_tendencia', 'acidentes_volatilidade'\n",
    "]\n",
    "\n",
    "df_features = df_features[features_colunas].copy()\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "# Target: nÃºmero total de acidentes\n",
    "target_values = df_features['total_acidentes'].values\n",
    "\n",
    "print(\"\\nğŸ“Š EstatÃ­sticas do target (nÃºmero total de acidentes por semana):\")\n",
    "print(f\"   Min: {target_values.min():.0f} acidentes\")\n",
    "print(f\"   Max: {target_values.max():.0f} acidentes\")\n",
    "print(f\"   MÃ©dia: {target_values.mean():.1f} acidentes\")\n",
    "print(f\"   Mediana: {np.median(target_values):.0f} acidentes\")\n",
    "print(f\"   Desvio padrÃ£o: {target_values.std():.1f}\")\n",
    "\n",
    "# Separar features de target\n",
    "features_sem_target = [col for col in features_colunas if col != 'total_acidentes']\n",
    "target_col = 'total_acidentes'\n",
    "\n",
    "# Normalizar apenas as FEATURES (sem o target)\n",
    "df_features_input = df_features[features_sem_target].copy()\n",
    "scaler_features = MinMaxScaler(feature_range=(0, 1))\n",
    "features_scaled = scaler_features.fit_transform(df_features_input.values)\n",
    "\n",
    "# TARGET tambÃ©m normalizado (para melhor treinamento da rede)\n",
    "scaler_target = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaled = scaler_target.fit_transform(target_values.reshape(-1, 1)).flatten()\n",
    "\n",
    "n_passos_para_tras = 8\n",
    "n_features = len(features_sem_target)\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(n_passos_para_tras, len(features_scaled)):\n",
    "    X.append(features_scaled[i-n_passos_para_tras:i, :])\n",
    "    y.append(target_scaled[i])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "print(f\"\\nâœ… SequÃªncias criadas para previsÃ£o de acidentes!\")\n",
    "print(f\"   Shape X: {X.shape}\")\n",
    "print(f\"   Shape y: {y.shape}\")\n",
    "print(f\"   Range de y normalizado: [{y.min():.3f}, {y.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ Dividindo dados temporalmente (respeitando ordem)...\")\n",
    "\n",
    "# Dividir dados temporalmente (85% treino, 15% validaÃ§Ã£o)\n",
    "split_index = int(len(X) * 0.85)\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "# Desnormalizar para mostrar estatÃ­sticas reais\n",
    "y_train_real = scaler_target.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_val_real = scaler_target.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"\\nğŸ“Š DivisÃ£o temporal:\")\n",
    "print(f\"   Treino: {len(X_train)} sequÃªncias ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ValidaÃ§Ã£o: {len(X_val)} sequÃªncias ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š EstatÃ­sticas de y_train (nÃºmero de acidentes):\")\n",
    "print(f\"   Min: {y_train_real.min():.0f} acidentes\")\n",
    "print(f\"   Max: {y_train_real.max():.0f} acidentes\")\n",
    "print(f\"   MÃ©dia: {y_train_real.mean():.1f} acidentes/semana\")\n",
    "print(f\"   Desvio: {y_train_real.std():.1f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š EstatÃ­sticas de y_val (nÃºmero de acidentes):\")\n",
    "print(f\"   Min: {y_val_real.min():.0f} acidentes\")\n",
    "print(f\"   Max: {y_val_real.max():.0f} acidentes\")\n",
    "print(f\"   MÃ©dia: {y_val_real.mean():.1f} acidentes/semana\")\n",
    "print(f\"   Desvio: {y_val_real.std():.1f}\")\n",
    "\n",
    "print(\"\\nâœ… Dados preparados para previsÃ£o de acidentes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"ğŸ—ï¸  Construindo modelo LSTM para PrevisÃ£o de Acidentes...\")\n",
    "\n",
    "# MODELO LSTM OTIMIZADO PARA SÃ‰RIES TEMPORAIS\n",
    "model = Sequential([\n",
    "    LSTM(units=128, return_sequences=True, input_shape=(n_passos_para_tras, n_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='linear')  # Output: valor contÃ­nuo\n",
    "])\n",
    "\n",
    "# OPTIMIZER\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_absolute_error',  # MAE: erro mÃ©dio em nÃºmero de acidentes\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "print(\"âœ… Modelo construÃ­do!\")\n",
    "print(\"   Arquitetura: LSTM 128 â†’ LSTM 64 â†’ Dense 32 â†’ Dense 16 â†’ Linear 1\")\n",
    "print(\"   Dropout: 0.2 (em todas as camadas)\")\n",
    "print(\"   Loss: MAE (Mean Absolute Error)\")\n",
    "print(\"   MÃ©tricas: MAE, MSE\")\n",
    "print(\"   Learning rate: 0.001\")\n",
    "model.summary()\n",
    "\n",
    "# CALLBACKS\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "print(\"\\nâœ… Callbacks configurados!\")\n",
    "print(\"   Early Stopping: patience=20\")\n",
    "print(\"   Reduce LR: patience=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ Passo 9: Treinamento do Modelo\n",
    "\n",
    "Treinamos o modelo com class weights para corrigir desbalanceamento. Monitoramos val_loss para evitar overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ TREINANDO MODELO LSTM\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“Š Prevendo nÃºmero total de acidentes por semana\")\n",
    "print(\"â±ï¸  Aguarde 10-20 minutos...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TREINAMENTO CONCLUÃDO!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Abordagem de Modelagem\n",
    "\n",
    "### Target: NÃºmero Total de Acidentes\n",
    "\n",
    "Escolhemos prever **contagem de acidentes** porque:\n",
    "\n",
    "âœ… **PadrÃµes temporais claros** - VariaÃ§Ã£o entre dias Ãºteis, fins de semana, sazonalidade  \n",
    "âœ… **Features histÃ³ricas sÃ£o preditivas** - Lags e mÃ©dias mÃ³veis capturam tendÃªncias  \n",
    "âœ… **LSTM ideal para sÃ©ries temporais** - Captura dependÃªncias de longo prazo  \n",
    "âœ… **AplicaÃ§Ã£o prÃ¡tica direta** - AlocaÃ§Ã£o de recursos (patrulhas, ambulÃ¢ncias)\n",
    "\n",
    "### Vantagens sobre ClassificaÃ§Ã£o\n",
    "\n",
    "ApÃ³s testes com classificaÃ§Ã£o (que nÃ£o funcionou bem):\n",
    "\n",
    "1. **Valores contÃ­nuos** - Prever 25 vs 30 acidentes Ã© mais Ãºtil que categorias\n",
    "2. **MÃ©tricas intuitivas** - MAE em nÃºmero de acidentes (ex: Â±5 acidentes/semana)\n",
    "3. **Variabilidade real** - Range maior permite modelo aprender melhor\n",
    "4. **Honestidade cientÃ­fica** - Mostra o que dados permitem prever\n",
    "\n",
    "### Arquitetura\n",
    "\n",
    "- **Input**: SequÃªncias de 8 semanas Ã— 11 features\n",
    "- **LSTM**: 2 camadas (128 â†’ 64) - captura padrÃµes temporais complexos\n",
    "- **Dense**: 2 camadas (32 â†’ 16) - processamento nÃ£o-linear\n",
    "- **Output**: 1 neurÃ´nio linear - nÃºmero de acidentes\n",
    "- **Loss**: MAE (Mean Absolute Error)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Passo 10: AvaliaÃ§Ã£o e MÃ©tricas\n",
    "\n",
    "Avaliamos o modelo com MAE (erro mÃ©dio em acidentes), RMSE, MAPE e RÂ². Comparamos com baseline (sempre prever mÃ©dia).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ˆ Passo 11: VisualizaÃ§Ãµes\n",
    "\n",
    "Geramos 6 grÃ¡ficos: curvas de aprendizagem (MAE/MSE), scatter plot real vs previsto, sÃ©rie temporal, distribuiÃ§Ã£o de erros e anÃ¡lise de resÃ­duos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"ğŸ“Š Avaliando modelo - PrevisÃ£o de Acidentes...\")\n",
    "\n",
    "# PrediÃ§Ãµes (normalizadas)\n",
    "y_pred_norm = model.predict(X_val, verbose=0).flatten()\n",
    "\n",
    "# Desnormalizar prediÃ§Ãµes e valores reais\n",
    "y_pred = scaler_target.inverse_transform(y_pred_norm.reshape(-1, 1)).flatten()\n",
    "y_val_real = scaler_target.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "y_train_real = scaler_target.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# MÃ©tricas em escala real (nÃºmero de acidentes)\n",
    "mae = mean_absolute_error(y_val_real, y_pred)\n",
    "mse = mean_squared_error(y_val_real, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_real, y_pred)\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((y_val_real - y_pred) / (y_val_real + 1))) * 100  # +1 para evitar divisÃ£o por zero\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ RESULTADOS FINAIS - PrevisÃ£o de NÃºmero de Acidentes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š MÃ©tricas de Erro:\")\n",
    "print(f\"   MAE (Mean Absolute Error): {mae:.2f} acidentes\")\n",
    "print(f\"   RMSE (Root Mean Squared Error): {rmse:.2f} acidentes\")\n",
    "print(f\"   MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Baseline: sempre prever a mÃ©dia\n",
    "baseline_pred = np.full_like(y_val_real, y_train_real.mean())\n",
    "baseline_mae = mean_absolute_error(y_val_real, baseline_pred)\n",
    "baseline_r2 = r2_score(y_val_real, baseline_pred)\n",
    "\n",
    "print(f\"\\nğŸ“Š ComparaÃ§Ã£o com Baseline (sempre prever mÃ©dia de {y_train_real.mean():.1f} acidentes):\")\n",
    "print(f\"   Baseline MAE: {baseline_mae:.2f} acidentes\")\n",
    "print(f\"   Baseline RÂ²: {baseline_r2:.4f}\")\n",
    "print(f\"   Nosso modelo MAE: {mae:.2f} acidentes âœ…\")\n",
    "print(f\"   Nosso modelo RÂ²: {r2:.4f} âœ…\")\n",
    "print(f\"   Melhoria: {((baseline_mae - mae)/baseline_mae*100):.1f}%\")\n",
    "\n",
    "# EstatÃ­sticas dos erros\n",
    "errors = np.abs(y_val_real - y_pred)\n",
    "print(f\"\\nğŸ“Š DistribuiÃ§Ã£o dos Erros Absolutos:\")\n",
    "print(f\"   MÃ­nimo: {errors.min():.2f} acidentes\")\n",
    "print(f\"   MÃ¡ximo: {errors.max():.2f} acidentes\")\n",
    "print(f\"   Mediana: {np.median(errors):.2f} acidentes\")\n",
    "print(f\"   75Âº percentil: {np.percentile(errors, 75):.2f} acidentes\")\n",
    "\n",
    "# Percentual de prediÃ§Ãµes com erro < 10 acidentes\n",
    "erro_threshold = 10\n",
    "pct_boas = (errors < erro_threshold).sum() / len(errors) * 100\n",
    "print(f\"\\nğŸ“Š Qualidade das PrediÃ§Ãµes:\")\n",
    "print(f\"   {pct_boas:.1f}% das prediÃ§Ãµes tÃªm erro < {erro_threshold} acidentes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ Passo 12: Salvamento do Modelo\n",
    "\n",
    "Salvamos o modelo treinado no formato `.keras` para uso futuro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Loss (MAE)\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Treino', color='blue', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='ValidaÃ§Ã£o', color='red', linewidth=2)\n",
    "plt.title('Curvas de Aprendizagem - MAE', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Ã‰pocas')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. MSE\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(history.history['mse'], label='Treino', color='blue', linewidth=2)\n",
    "plt.plot(history.history['val_mse'], label='ValidaÃ§Ã£o', color='red', linewidth=2)\n",
    "plt.title('Curvas de Aprendizagem - MSE', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Ã‰pocas')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Real vs Previsto (Scatter Plot)\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.scatter(y_val_real, y_pred, alpha=0.5, s=30)\n",
    "plt.plot([y_val_real.min(), y_val_real.max()], [y_val_real.min(), y_val_real.max()], 'r--', lw=2, label='Linha Perfeita')\n",
    "plt.title('Real vs Previsto', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('NÃºmero Real de Acidentes')\n",
    "plt.ylabel('NÃºmero Previsto de Acidentes')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. SÃ©rie Temporal: Real vs Previsto\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(y_val_real, label='Real', linewidth=2, alpha=0.7, marker='o', markersize=4)\n",
    "plt.plot(y_pred, label='Previsto', linewidth=2, alpha=0.7, linestyle='--', marker='x', markersize=4)\n",
    "plt.title('ComparaÃ§Ã£o Temporal', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('NÃºmero de Acidentes')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. DistribuiÃ§Ã£o dos Erros\n",
    "plt.subplot(3, 2, 5)\n",
    "errors = y_val_real - y_pred\n",
    "plt.hist(errors, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Erro Zero')\n",
    "plt.title('DistribuiÃ§Ã£o dos Erros (ResÃ­duos)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Erro (Real - Previsto) [acidentes]')\n",
    "plt.ylabel('FrequÃªncia')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. ResÃ­duos vs Valores Previstos\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.scatter(y_pred, errors, alpha=0.5, s=30, color='coral')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.title('ResÃ­duos vs Valores Previstos', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('NÃºmero Previsto de Acidentes')\n",
    "plt.ylabel('ResÃ­duo (Real - Previsto) [acidentes]')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… VisualizaÃ§Ãµes geradas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'modelo_lstm_classificacao_risco.keras'\n",
    "model.save(model_filename)\n",
    "print(f\"ğŸ’¾ Modelo salvo: '{model_filename}'\")\n",
    "print(\"\\nâœ… Projeto concluÃ­do!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
